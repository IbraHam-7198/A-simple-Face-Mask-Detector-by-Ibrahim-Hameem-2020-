{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from keras_preprocessing import image\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the pre-trained cascades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ibrahim Hameem\\Desktop\\Machine Learning\\7. Neural Nets\\Convolutional Neural Network\\Project Face Mask\n",
      "\n",
      "C:\\Users\\Ibrahim Hameem\\Desktop\\Machine Learning\\7. Neural Nets\\Convolutional Neural Network\\Computer_Vision_A_Z_Template_Folder\\Module_1_Face_Recognition\n"
     ]
    }
   ],
   "source": [
    "print (os.getcwd())\n",
    "os.chdir('C:\\\\Users\\\\Ibrahim Hameem\\\\Desktop\\\\Machine Learning\\\\7. Neural Nets\\\\Convolutional Neural Network\\\\Computer_Vision_A_Z_Template_Folder\\\\Module_1_Face_Recognition')\n",
    "print ('')\n",
    "print (os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading a custome pre-trained version of MobileNet V2 for image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ibrahim Hameem\\Desktop\\Machine Learning\\7. Neural Nets\\Convolutional Neural Network\\Project Face Mask\n"
     ]
    }
   ],
   "source": [
    "#Change the working directory to the location within your computer, where the pre-trained MobileNet V2 is saved \n",
    "os.chdir('C:\\\\Users\\\\Ibrahim Hameem\\\\Desktop\\\\Machine Learning\\\\7. Neural Nets\\\\Convolutional Neural Network\\\\Project Face Mask')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the pre-trained model\n",
    "base_model = tf.keras.models.load_model('mask_model_pre-trained_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We lock the models, such that the imported model is not trainable\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definining a detection function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mask_dict = {'No Mask or Incorrectly masked':1, 'Mask':0}\n",
    "Color_dict = {1:(0,0,255), 0:(0,255,0)}\n",
    "prediction_threshold = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskdetect (gray, frame):\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 7)\n",
    "    for (x,y,w,h) in faces:\n",
    "        roi_color = frame[y-60:y-60+h+120,x-15:x-15+w+30]\n",
    "        \n",
    "        resized = cv2.resize(roi_color,(224,224))\n",
    "        test_image = image.img_to_array(resized)\n",
    "        test_image = np.expand_dims(test_image, axis = 0)\n",
    "        result = base_model.predict(test_image)\n",
    "    \n",
    "        if result[0][0] >= prediction_threshold:\n",
    "            prediction = 'No Mask or Incorrectly masked'\n",
    "        else:\n",
    "            prediction = 'Mask'\n",
    "        \n",
    "        frame = cv2.rectangle(frame, (x-20,y-70), (x-20+w+40, y-70+h+110),Color_dict[Mask_dict[prediction]] ,3)\n",
    "        frame = cv2.rectangle(frame,(x-110,y-90), (x-110+w+220, y-130),Color_dict[Mask_dict[prediction]],-1)\n",
    "        frame = cv2.putText(frame,prediction, (x-100, y-100),cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,255,255),2)\n",
    "        \n",
    "        if prediction == 'No Mask or Incorrectly masked':\n",
    "            frame = cv2.putText(frame,str(np.round(result[0][0]*100,2)) + '%', (x+200, y-100),cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,255,255),2)\n",
    "        else:\n",
    "            frame =cv2.putText(frame,str(np.round((1-result[0][0])*100,2)) + '%', (x+200, y-100),cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,255,255),2)\n",
    "         \n",
    "    return frame     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _,frame = video_capture.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    canvas = maskdetect(gray, frame)\n",
    "    cv2.imshow('Video', canvas)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord ('q'):\n",
    "        break\n",
    "        \n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
